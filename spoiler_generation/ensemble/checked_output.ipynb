{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoiler generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mateusz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mateusz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Mateusz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spoiler_generation.utils.dataset_class import Dataset\n",
    "import pandas as pd\n",
    "from spoiler_generation.utils.stats import prepare_stats, calculate_bleu\n",
    "import mlflow\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is private\n",
    "dataset = load_dataset(\"MateuszW/clickbait_spoiling_test\")\n",
    "test_df = pd.DataFrame(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_outputs = load_dataset(\n",
    "    \"MateuszW/spoiler_generation\",\n",
    "    data_files={\n",
    "        \"baseline\": \"models_output/deberta-baseline_output.csv\",\n",
    "        \"deberta_paqott\": \"models_output/deberta-paqott_output.csv\",\n",
    "        \"llama_pwot\": \"models_output/llama-pwot_output.csv\",\n",
    "        \"vicuna_pwot\": \"models_output/vicuna-pwot_output.csv\",\n",
    "        \"opt_pwot\": \"models_output/opt-pwot_output.csv\",\n",
    "        \"llama_pwt\": \"models_output/llama-pwt_output.csv\",\n",
    "        \"vicuna_pwt\": \"models_output/vicuna-pwt_output.csv\",\n",
    "        \"opt_pwt\": \"models_output/opt-pwt_output.csv\",\n",
    "        \"vicuna_ppt\": \"models_output/vicuna-ppt_output.csv\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    baseline: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    deberta_paqott: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    llama_pwot: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    vicuna_pwot: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    llama_pwt: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    vicuna_pwt: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    opt_pwt: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    vicuna_ppt: Dataset({\n",
       "        features: ['id', 'spoiler'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.3789261019434709\n",
      "deberta_paqott 0.38212501050366765\n",
      "llama_pwot 0.3210898228482464\n",
      "vicuna_pwot 0.3305139476447337\n",
      "llama_pwt 0.3758915129293975\n",
      "vicuna_pwt 0.3869613288383001\n",
      "opt_pwt 0.33757424975291617\n",
      "vicuna_ppt 0.39901931587160233\n"
     ]
    }
   ],
   "source": [
    "for output_name in models_outputs.keys():\n",
    "    print(output_name, calculate_bleu(test_df, pd.DataFrame(models_outputs[output_name])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_df = test_df.loc[test_df[\"type\"] == \"phrase\"]\n",
    "prepare_stats(phrase_df, pd.DataFrame(models_outputs[\"baseline\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9423626642982447,\n",
       " 'recall': 0.9435541247926987,\n",
       " 'f1': 0.9425771849375244}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_score_val = calculate_bertscore(phrase_df, output)\n",
    "bert_metrics_mean(bert_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23160457153151287"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_df = test_df.loc[test_df[\"tags\"] == \"passage\"]\n",
    "calculate_bleu(passage_df, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8977760011445796,\n",
       " 'recall': 0.874899429363885,\n",
       " 'f1': 0.8857718703172934}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_score_val = calculate_bertscore(passage_df, output)\n",
    "bert_metrics_mean(bert_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0766925771830039"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df = test_df.loc[test_df[\"tags\"] == \"multi\"]\n",
    "calculate_bleu(multi_df, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8889400486288399,\n",
       " 'recall': 0.8302655946249249,\n",
       " 'f1': 0.8579819113358684}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_score_val = calculate_bertscore(multi_df, output)\n",
    "bert_metrics_mean(bert_score_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/mateusz15wozny/master_thesis/data/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "with open(\"/home/mateusz15wozny/master_thesis/data/st_output.json\", \"r\") as f:\n",
    "    output = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoilers = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    spoilers.append(test_data[i][\"qas\"][0][\"answers\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(spoilers, columns=[\"spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_spoilers_lists = []\n",
    "for i in range(len(output)):\n",
    "    pred_spoilers_lists.append(sorted(output[i][\"answer\"], key=lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_spoilers = []\n",
    "map_dict = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}\n",
    "for i in range(len(output)):\n",
    "    index = min(map_dict[test_data[i][\"tag\"]], len(pred_spoilers_lists[i]) - 1)\n",
    "    if pred_spoilers_lists[i][index] == \"\" and len(pred_spoilers_lists[i]) < index + 1:\n",
    "        index += 1\n",
    "    spoiler = pred_spoilers_lists[i][index]\n",
    "    pred_spoilers.append(spoiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_spoilers, columns=[\"spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(run_name=\"Simple transformers\") as run:\n",
    "#     run_id = run.info.run_id\n",
    "stats = prepare_stats(test_df, pred_df)\n",
    "log_to_mlflow(\"\", stats, \"afee9b1e11d148c28cbbff407896a53c\")\n",
    "# stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 1.3B peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\")\n",
    "test_df = test.df\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/data/opt_generation/opt-1.3B_peft_output.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7948054869174958,\n",
       " 'recall': 0.7785088661909103,\n",
       " 'f1': 0.7825760175585746}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import bert_metrics_mean, calculate_bertscore\n",
    "\n",
    "with mlflow.start_run(run_name=\"OPT 1.3B peft\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"output_dir\", \"/home/mateusz15wozny/master_thesis/models/opt-peft-v2\")\n",
    "stats = bert_metrics_mean(calculate_bertscore(test_df, output))\n",
    "log_to_mlflow(\"\", stats, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(test_df, output)\n",
    "log_to_mlflow(\"\", {\"meteor\": meteor}, \"b665a1fe3e3c49fa9bf54417bc52e7d1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 13B peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\")\n",
    "test_df = test.df\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/opt-peft-13B/output_v2.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_mlflow(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/opt-peft-13B\",\n",
    "    prepare_stats(test_df, output),\n",
    ")\n",
    "# prepare_stats(test_df, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(test_df, output)\n",
    "log_to_mlflow(\"/home/mateusz15wozny/master_thesis/models/opt-peft-13B\", {\"meteor\": meteor})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 13B with type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/opt-13b-with-type/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.33858605370621186,\n",
       " 'precision': 0.8977188437581062,\n",
       " 'recall': 0.8937850190401078,\n",
       " 'f1': 0.8950101483464241,\n",
       " 'exact_match': 0.248,\n",
       " 'meteor': 0.4345849540181727}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_stats(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_mlflow(\"models/opt-13b-with-type\", prepare_stats(test, output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-finetuned/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.3770354374520436,\n",
       " 'precision': 0.8946512819528579,\n",
       " 'recall': 0.9012328633069993,\n",
       " 'f1': 0.897447925388813,\n",
       " 'exact_match': 0.268}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_to_mlflow(\"models/llama-13b-finetuned\", prepare_stats(test, output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-without-type/output.csv\")\n",
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.32212797292509027,\n",
       " 'precision': 0.8899407665133476,\n",
       " 'recall': 0.8877390567660332,\n",
       " 'f1': 0.8882314289808273,\n",
       " 'exact_match': 0.243,\n",
       " 'meteor': 0.40783805965104264}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_stats(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_mlflow(\"models/llama-13b-without-type\", prepare_stats(test, output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vicuna 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without typee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-without-type/output.csv\")\n",
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40015284106570886"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import calculate_bleu\n",
    "\n",
    "calculate_bleu(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.33163400043252533,\n",
       " 'precision': 0.8863940492272377,\n",
       " 'recall': 0.8869956572651863,\n",
       " 'f1': 0.8860925446748733,\n",
       " 'exact_match': 0.234,\n",
       " 'meteor': 0.41757068006087084}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_stats(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "log_to_mlflow(\"models/vicuna-13b-without-type\", prepare_stats(test, output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\")\n",
    "output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "test[\"spoiler\"] = test[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40015284106570886"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import calculate_bleu\n",
    "\n",
    "calculate_bleu(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "log_to_mlflow(\"models/vicuna-13b-new-prompt\", prepare_stats(test, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(test, output)\n",
    "log_to_mlflow(\"models/vicuna-13b-new-prompt\", {\"meteor\": meteor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz15wozny/master_thesis/results/stats.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_spoiler[\"spoiler\"] = true_spoiler[\"spoiler\"].apply(preprocess_func)\n"
     ]
    }
   ],
   "source": [
    "from stats import calculate_bleu\n",
    "\n",
    "for typ in [\"phrase\", \"passage\", \"multi\"]:\n",
    "    bleus[\"vicuna\"].update({typ: calculate_bleu(test[test[\"type\"] == typ], output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/deberta-v3-trial-3\"\n",
    "deberta_output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>mixed = original_df.loc[test[<span style=\"color: #808000; text-decoration-color: #808000\">\"id\"</span>] - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].reset_index(drop=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>vicuna_output = vicuna_output.loc[test[<span style=\"color: #808000; text-decoration-color: #808000\">\"id\"</span>] - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].reset_index(drop=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 deberta_output= deberta_output.loc[test[<span style=\"color: #808000; text-decoration-color: #808000\">\"id\"</span>]-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].reset_index(drop=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">107</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1070 │   │   │   </span>axis = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.axis <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1071 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 │   │   │   </span>maybe_callable = com.apply_if_callable(key, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1073 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_axis(maybe_callable, axis=axis)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_is_scalar_access</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, key: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">130</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_getitem_axis</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1298 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(key, <span style=\"color: #808000; text-decoration-color: #808000\">\"ndim\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key.ndim &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1299 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Cannot index with multidimensional key\"</span>)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1300 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1301 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_iterable(key, axis=axis)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1302 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1303 │   │   │   # nested tuple slicing</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1304 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_nested_tuple(key, labels):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">123</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_getitem_iterable</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1236 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._validate_key(key, axis)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1237 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1238 │   │   # A collection of keys</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1239 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>keyarr, indexer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_listlike_indexer(key, axis)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1240 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj._reindex_with_indexers(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1241 │   │   │   </span>{axis: [keyarr, indexer]}, copy=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, allow_dups=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1242 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">indexing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">143</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_listlike_indexer</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1429 │   │   </span>ax = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj._get_axis(axis)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1430 │   │   </span>axis_name = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj._get_axis_name(axis)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1431 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1432 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>keyarr, indexer = ax._get_indexer_strict(key, axis_name)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1433 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1434 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> keyarr, indexer                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1435 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6070</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_indexer_strict</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6067 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6068 │   │   │   </span>keyarr, indexer, new_indexer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reindex_non_unique(keyarr)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6069 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6070 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._raise_if_missing(keyarr, indexer, axis_name)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6071 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6072 │   │   </span>keyarr = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.take(indexer)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6073 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(key, Index):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6133</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_raise_if_missing</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6130 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"None of [{</span>key<span style=\"color: #808000; text-decoration-color: #808000\">}] are in the [{</span>axis_name<span style=\"color: #808000; text-decoration-color: #808000\">}]\"</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6131 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6132 │   │   │   </span>not_found = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(ensure_index(key)[missing_mask.nonzero()[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]].unique())       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6133 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>not_found<span style=\"color: #808000; text-decoration-color: #808000\">} not in index\"</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6134 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6135 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@overload</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6136 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_indexer_non_comparable</span>(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'[988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999] not in index'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mmixed = original_df.loc[test[\u001b[33m\"\u001b[0m\u001b[33mid\u001b[0m\u001b[33m\"\u001b[0m] - \u001b[94m1\u001b[0m].reset_index(drop=\u001b[94mTrue\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mvicuna_output = vicuna_output.loc[test[\u001b[33m\"\u001b[0m\u001b[33mid\u001b[0m\u001b[33m\"\u001b[0m] - \u001b[94m1\u001b[0m].reset_index(drop=\u001b[94mTrue\u001b[0m)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 deberta_output= deberta_output.loc[test[\u001b[33m\"\u001b[0m\u001b[33mid\u001b[0m\u001b[33m\"\u001b[0m]-\u001b[94m1\u001b[0m].reset_index(drop=\u001b[94mTrue\u001b[0m)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m107\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m3\u001b[0m in \u001b[92m__getitem__\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1070 \u001b[0m\u001b[2m│   │   │   \u001b[0maxis = \u001b[96mself\u001b[0m.axis \u001b[95mor\u001b[0m \u001b[94m0\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1071 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2m│   │   │   \u001b[0mmaybe_callable = com.apply_if_callable(key, \u001b[96mself\u001b[0m.obj)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1073 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_axis(maybe_callable, axis=axis)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1075 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_is_scalar_access\u001b[0m(\u001b[96mself\u001b[0m, key: \u001b[96mtuple\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m130\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_getitem_axis\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1298 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(key, \u001b[33m\"\u001b[0m\u001b[33mndim\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m key.ndim > \u001b[94m1\u001b[0m:                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1299 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mCannot index with multidimensional key\u001b[0m\u001b[33m\"\u001b[0m)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1300 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1301 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_iterable(key, axis=axis)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1302 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1303 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# nested tuple slicing\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1304 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m is_nested_tuple(key, labels):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m123\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m9\u001b[0m in \u001b[92m_getitem_iterable\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1236 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._validate_key(key, axis)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1237 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1238 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# A collection of keys\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1239 \u001b[2m│   │   \u001b[0mkeyarr, indexer = \u001b[96mself\u001b[0m._get_listlike_indexer(key, axis)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1240 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.obj._reindex_with_indexers(                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1241 \u001b[0m\u001b[2m│   │   │   \u001b[0m{axis: [keyarr, indexer]}, copy=\u001b[94mTrue\u001b[0m, allow_dups=\u001b[94mTrue\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1242 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mindexing.py\u001b[0m:\u001b[94m143\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m2\u001b[0m in \u001b[92m_get_listlike_indexer\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1429 \u001b[0m\u001b[2m│   │   \u001b[0max = \u001b[96mself\u001b[0m.obj._get_axis(axis)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1430 \u001b[0m\u001b[2m│   │   \u001b[0maxis_name = \u001b[96mself\u001b[0m.obj._get_axis_name(axis)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1431 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1432 \u001b[2m│   │   \u001b[0mkeyarr, indexer = ax._get_indexer_strict(key, axis_name)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1433 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1434 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m keyarr, indexer                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1435 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m6070\u001b[0m in \u001b[92m_get_indexer_strict\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6067 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6068 \u001b[0m\u001b[2m│   │   │   \u001b[0mkeyarr, indexer, new_indexer = \u001b[96mself\u001b[0m._reindex_non_unique(keyarr)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6069 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6070 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._raise_if_missing(keyarr, indexer, axis_name)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6071 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6072 \u001b[0m\u001b[2m│   │   \u001b[0mkeyarr = \u001b[96mself\u001b[0m.take(indexer)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6073 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(key, Index):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m6133\u001b[0m in \u001b[92m_raise_if_missing\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mNone of [\u001b[0m\u001b[33m{\u001b[0mkey\u001b[33m}\u001b[0m\u001b[33m] are in the [\u001b[0m\u001b[33m{\u001b[0maxis_name\u001b[33m}\u001b[0m\u001b[33m]\u001b[0m\u001b[33m\"\u001b[0m)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6131 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6132 \u001b[0m\u001b[2m│   │   │   \u001b[0mnot_found = \u001b[96mlist\u001b[0m(ensure_index(key)[missing_mask.nonzero()[\u001b[94m0\u001b[0m]].unique())       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6133 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mnot_found\u001b[33m}\u001b[0m\u001b[33m not in index\u001b[0m\u001b[33m\"\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6134 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6135 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@overload\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_indexer_non_comparable\u001b[0m(                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999\u001b[0m\u001b[32m]\u001b[0m\u001b[32m not in index'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mixed = original_df.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "vicuna_output = vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "deberta_output = deberta_output.loc[test[\"id\"] - 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(\n",
    "    [\n",
    "        deberta_output[mixed[\"tags\"] != \"multi\"][\"spoiler\"],\n",
    "        vicuna_output[mixed[\"tags\"] == \"multi\"][\"spoiler\"],\n",
    "    ]\n",
    ").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39447341398784613"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu(mixed, merged_df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/mateusz15wozny/master_thesis/results/all_spoilers_with_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vicuna\"] = output[\"spoiler\"]\n",
    "df[\"type\"] = test[\"type\"]\n",
    "df.to_csv(\"/home/mateusz15wozny/master_thesis/results/all_spoilers_with_gt.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta squad v2 no Vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stats import prepare_stats, log_to_mlflow\n",
    "\n",
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test.json\")\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/roberta-base-squad2-finetuned-no-vicuna\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(output_dir, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(output_dir, {\"meteor\": meteor})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta squad with vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/roberta-base-squad2-finetuned\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(output_dir, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(output_dir, {\"meteor\": meteor})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta with concatenated vicuna and clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test_concatenated.json\")\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/roberta-base_concatenated-v2\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(output_dir, {\"meteor\": meteor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(output_dir, stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/data/hf_qa/roberta_deepset_base_output.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run(run_name=\"Roberta base without finetuning\") as run:\n",
    "#     run_id = run.info.run_id\n",
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(\"\", {\"meteor\": meteor}, \"f8632407526f4f9a87d3e34a97e39381\")\n",
    "# log_to_mlflow(\"\", stats, run_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta with vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/deberta-v3-trial-3\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz15wozny/master_thesis/results/stats.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_spoiler[\"spoiler\"] = true_spoiler[\"spoiler\"].apply(preprocess_func)\n",
      "/home/mateusz15wozny/master_thesis/results/stats.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_spoiler[\"spoiler\"] = true_spoiler[\"spoiler\"].apply(preprocess_func)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.42424742287009065,\n",
       " 'precision': 0.9133387114989963,\n",
       " 'recall': 0.906181343211003,\n",
       " 'f1': 0.9091662232940262,\n",
       " 'exact_match': 0.32186732186732187}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed = original_df.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "prepare_stats(mixed[mixed[\"tags\"] != \"multi\"], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gwyneth paltrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>filming the next nicholas spark film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>javale mcgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>996</td>\n",
       "      <td>all along the watchtower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>997</td>\n",
       "      <td>1 catch it on a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>998</td>\n",
       "      <td>total lunar eclipse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>999</td>\n",
       "      <td>tami erin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1000</td>\n",
       "      <td>18 amber wood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uuid                               spoiler\n",
       "0       1                                  soap\n",
       "1       2                       gwyneth paltrow\n",
       "2       3  filming the next nicholas spark film\n",
       "3       4                          javale mcgee\n",
       "4       5                                  cora\n",
       "..    ...                                   ...\n",
       "983   996              all along the watchtower\n",
       "984   997              1 catch it on a good day\n",
       "985   998                   total lunar eclipse\n",
       "986   999                             tami erin\n",
       "987  1000                         18 amber wood\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gwyneth paltrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>filming the next nicholas spark film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>javale mcgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>996</td>\n",
       "      <td>all along the watchtower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>997</td>\n",
       "      <td>1 catch it on a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>998</td>\n",
       "      <td>total lunar eclipse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>999</td>\n",
       "      <td>tami erin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1000</td>\n",
       "      <td>18 amber wood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uuid                               spoiler\n",
       "0       1                                  soap\n",
       "1       2                       gwyneth paltrow\n",
       "2       3  filming the next nicholas spark film\n",
       "3       4                          javale mcgee\n",
       "4       5                                  cora\n",
       "..    ...                                   ...\n",
       "983   996              all along the watchtower\n",
       "984   997              1 catch it on a good day\n",
       "985   998                   total lunar eclipse\n",
       "986   999                             tami erin\n",
       "987  1000                         18 amber wood\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(output_dir, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(output_dir, {\"meteor\": meteor})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta without vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test.json\")\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/deberta-v3-no-vicuna\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)\n",
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(output_dir, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(output_dir, {\"meteor\": meteor})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta with concatenated vicuna and clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test_concatenated.json\")\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/deberta-base-from-zero\"\n",
    "output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)\n",
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Deberta from zero with conc post and clickbait\") as run:\n",
    "    pass\n",
    "log_to_mlflow(\"\", prepare_stats(df, output), run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">range.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">391</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 388 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_integer(key) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> (is_float(key) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key.is_integer()):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 389 │   │   │   │   </span>new_key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(key)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 390 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 391 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._range.index(new_key)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 392 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 393 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 394 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_indexing_error(key)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> is not in range\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 log_to_mlflow(output_dir, prepare_stats(df, output))                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/results/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">stats.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">109</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">log_to_mlflow</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">log_to_mlflow</span>(output_dir, metrics, run_id=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 │   </span>mlflow.set_tracking_uri(<span style=\"color: #808000; text-decoration-color: #808000\">\"/home/mateusz15wozny/master_thesis/mlruns\"</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> run_id <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>109 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>run_id = mlflow.search_runs(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"0\"</span>, filter_string=<span style=\"color: #808000; text-decoration-color: #808000\">f\"params.output_dir='{</span>output_dir<span style=\"color: #808000; text-decoration-color: #808000\">}'\"</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   </span>)[<span style=\"color: #808000; text-decoration-color: #808000\">\"run_id\"</span>][<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> mlflow.start_run(run_id=run_id):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">series.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">981</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 978 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._values[key]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 979 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 980 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> key_is_scalar:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 981 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_value(key)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 982 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 983 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_hashable(key):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 984 │   │   │   # Otherwise index.get_value will raise InvalidIndexError</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">series.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1089</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_value</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1086 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._values[label]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1087 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1088 │   │   # Similar to Index.get_value, but we do not fall back to positional</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1089 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loc = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.index.get_loc(label)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1090 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.index._get_values_for_loc(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, loc, label)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1091 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1092 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__setitem__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, key, value) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">range.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">393</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 390 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 391 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._range.index(new_key)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 392 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 393 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 394 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_indexing_error(key)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 395 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 396 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().get_loc(key, method=method, tolerance=tolerance)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mrange.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m391\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 388 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m is_integer(key) \u001b[95mor\u001b[0m (is_float(key) \u001b[95mand\u001b[0m key.is_integer()):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 389 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnew_key = \u001b[96mint\u001b[0m(key)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 390 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 391 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._range.index(new_key)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 392 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mValueError\u001b[0m \u001b[94mas\u001b[0m err:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 393 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 394 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._check_indexing_error(key)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0m\u001b[1;36m0\u001b[0m is not in range\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 log_to_mlflow(output_dir, prepare_stats(df, output))                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/results/\u001b[0m\u001b[1;33mstats.py\u001b[0m:\u001b[94m109\u001b[0m in \u001b[92mlog_to_mlflow\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlog_to_mlflow\u001b[0m(output_dir, metrics, run_id=\u001b[94mNone\u001b[0m):                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   \u001b[0mmlflow.set_tracking_uri(\u001b[33m\"\u001b[0m\u001b[33m/home/mateusz15wozny/master_thesis/mlruns\u001b[0m\u001b[33m\"\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m run_id \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m109 \u001b[2m│   │   \u001b[0mrun_id = mlflow.search_runs(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\"\u001b[0m, filter_string=\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mparams.output_dir=\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0moutput_dir\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m)[\u001b[33m\"\u001b[0m\u001b[33mrun_id\u001b[0m\u001b[33m\"\u001b[0m][\u001b[94m0\u001b[0m]                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m mlflow.start_run(run_id=run_id):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mseries.py\u001b[0m:\u001b[94m981\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__getitem__\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 978 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._values[key]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 980 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m key_is_scalar:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 981 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._get_value(key)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 982 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 983 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m is_hashable(key):                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 984 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Otherwise index.get_value will raise InvalidIndexError\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mseries.py\u001b[0m:\u001b[94m1089\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_get_value\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1086 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._values[label]                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1087 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1088 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1089 \u001b[2m│   │   \u001b[0mloc = \u001b[96mself\u001b[0m.index.get_loc(label)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1090 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.index._get_values_for_loc(\u001b[96mself\u001b[0m, loc, label)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1091 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1092 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__setitem__\u001b[0m(\u001b[96mself\u001b[0m, key, value) -> \u001b[94mNone\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/mateusz15wozny/master_thesis/.env/lib/python3.10/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mrange.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m393\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 390 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 391 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._range.index(new_key)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 392 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mValueError\u001b[0m \u001b[94mas\u001b[0m err:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 393 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 394 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._check_indexing_error(key)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 395 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 396 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().get_loc(key, method=method, tolerance=tolerance)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not multi deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_not_multi = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/type_based_clf/not_multi/test.json\")\n",
    "output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta/checkpoint-1293/output.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "test_multi = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "\n",
    "test_not_multi[\"spoiler\"] = test_not_multi[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "test_multi = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "original_df = original_df.loc[test_multi[\"id\"] - 1].reset_index(drop=True)\n",
    "vicuna_output = vicuna_output.loc[test_multi[\"id\"] - 1].reset_index(drop=True)[original_df[\"tags\"] == \"multi\"]\n",
    "test_multi = test_multi[original_df[\"tags\"] == \"multi\"]\n",
    "test_multi[\"spoiler\"] = test_multi[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"spoiler\"], vicuna_output[\"spoiler\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.concat([test_not_multi[\"spoiler\"], test_multi[\"spoiler\"]]).to_frame().reset_index(drop=True)\n",
    "pred = pd.concat([output[\"spoiler\"], vicuna_output[\"spoiler\"]]).to_frame().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4227937201349781,\n",
       " 'precision': 0.9102973761828804,\n",
       " 'recall': 0.908094981903972,\n",
       " 'f1': 0.9086293058115461,\n",
       " 'exact_match': 0.3026315789473684,\n",
       " 'meteor': 0.5082325180947119}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_stats(ref, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_mlflow(\"models/not-multi-deberta\", {\"meteor\": calculate_meteor(ref, pred)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not multi  deberta on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test.json\")\n",
    "output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta-v2/full_output.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prepare_stats(df, pd.DataFrame(output, columns=[\"spoiler\"]))\n",
    "search_df = pd.DataFrame([results])\n",
    "path = \"/home/mateusz15wozny/master_thesis/results/tables/qa_models_with_generated_questions.csv\"\n",
    "df = pd.read_csv(path)\n",
    "search_df[\"model_name\"] = \"deberta-finetuned-with-post-question\"\n",
    "search_df[\"description\"] = \"Model finetune with clickbait post, generated questions and article\"\n",
    "search_df[\"use_type\"] = True\n",
    "search_df = search_df[[\"model_name\", \"bleu\", \"meteor\", \"exact_match\", \"recall\", \"f1\", \"precision\", \"description\", \"use_type\"]]\n",
    "\n",
    "pd.concat([df, search_df], ignore_index=True).to_csv(path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/data/hf_qa/deberta_deepset_base_output.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "df = pd.DataFrame()\n",
    "df[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(df, output)\n",
    "log_to_mlflow(\"\", {\"meteor\": meteor}, \"ce5e2977a5b14ff3bc2aed760d9060eb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Deberta deepset without finetuning\") as run:\n",
    "    run_id = run.info.run_id\n",
    "stats = prepare_stats(df, output)\n",
    "log_to_mlflow(\"\", stats, run_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spoiler_generation.utils.dataset_class import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "llama_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-finetuned/output.csv\")\n",
    "opt_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/opt-13b-with-type/output.csv\").fillna(\"\")\n",
    "\n",
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "output_dir = \"/home/mateusz15wozny/master_thesis/models/deberta-v3-trial-3\"\n",
    "deberta_output = pd.read_json(f\"{output_dir}/output.jsonl\", lines=True)\n",
    "deberta_conc = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta-v2/full_output.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_baseline = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/data/baseline/baseline2_output.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "deberta_baseline = deberta_baseline.loc[test[\"id\"] - 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))\n",
    "vicuna_output = vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "vicunav2_output = vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "llama_output = llama_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "opt_output = opt_output.loc[test[\"id\"] - 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>soap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gwyneth paltrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hiddleswift are actually just filming the next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>javale mcgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>996</td>\n",
       "      <td>all along the watchtower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>997</td>\n",
       "      <td>1 catch it on a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>998</td>\n",
       "      <td>total lunar eclipse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>999</td>\n",
       "      <td>tami erin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1000</td>\n",
       "      <td>18 amber wood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uuid                                            spoiler\n",
       "0       1                                               soap\n",
       "1       2                                    gwyneth paltrow\n",
       "2       3  hiddleswift are actually just filming the next...\n",
       "3       4                                       javale mcgee\n",
       "4       5                                               cora\n",
       "..    ...                                                ...\n",
       "983   996                           all along the watchtower\n",
       "984   997                           1 catch it on a good day\n",
       "985   998                                total lunar eclipse\n",
       "986   999                                          tami erin\n",
       "987  1000                                      18 amber wood\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        llama_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        vicuna_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        opt_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        # vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988, 4)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected using regressor between not multi deberta, llama and vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test_2.json\")\n",
    "test_not_multi = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/type_based_clf/not_multi/test.json\")\n",
    "\n",
    "not_multi_vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "not_multi_vicunav2_output = (\n",
    "    not_multi_vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] != \"multi\"].reset_index(drop=True)\n",
    ")\n",
    "multi_vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "multi_vicunav2_output = multi_vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "multi_vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "multi_vicuna_output = multi_vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "multi_llama_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-finetuned/output.csv\")\n",
    "multi_llama_output = multi_llama_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "not_multi_output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta/checkpoint-1293/output.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        multi_vicuna_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        # multi_llama_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_multi_merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        not_multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        not_multi_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check best score selecting by max bleu per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bleu = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_not_multi[\"spoiler\"] = test_not_multi[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))\n",
    "not_multi_merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        not_multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        not_multi_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        test_not_multi[\"spoiler\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def calc_bleu(true_spoiler, predicted_spoiler):\n",
    "    bleu_score = []\n",
    "    for reference, hypothesis in zip(true_spoiler, predicted_spoiler):\n",
    "        try:\n",
    "            val = bleu.compute(\n",
    "                predictions=[hypothesis],\n",
    "                references=[[reference]],\n",
    "                max_order=min(4, len(reference.split(\" \"))),\n",
    "            )[\"bleu\"]\n",
    "        except ZeroDivisionError:\n",
    "            val = 0\n",
    "        bleu_score.append(val)\n",
    "    return bleu_score\n",
    "\n",
    "\n",
    "best_bleu_not_multi = pd.DataFrame(\n",
    "    zip(\n",
    "        calc_bleu(test_not_multi[\"spoiler\"], not_multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "        calc_bleu(test_not_multi[\"spoiler\"], not_multi_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "    )\n",
    ")\n",
    "best_bleu_multi = pd.DataFrame(\n",
    "    zip(\n",
    "        calc_bleu(test_multi[\"spoiler\"], multi_vicuna_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "        calc_bleu(test_multi[\"spoiler\"], multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "        calc_bleu(test_multi[\"spoiler\"], multi_llama_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.434904\n",
       " 1    0.458596\n",
       " dtype: float64,\n",
       " 0    0.255524\n",
       " 1    0.260252\n",
       " 2    0.255637\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bleu_not_multi.mean(axis=0), best_bleu_multi.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5816430706710656, 0.35554409568734235)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bleu_not_multi.max(axis=1).mean(), best_bleu_multi.max(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_possible_bleu = pd.concat([best_bleu_not_multi.max(axis=1), best_bleu_multi.max(axis=1)]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best possible bleu to achive with ~multi deberta and vicuna and multi vicuna v1,v2 and llama"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5418240204208956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = \"/home/mateusz15wozny/master_thesis/spoiler_generation/regressor/deberta-base-v3\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=1).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"For given question:\\n {} \\nanswer:\\n {} \\ncontext:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [01:39<00:00,  8.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "not_multi_selected_spoilers = []\n",
    "for n in tqdm(range(not_multi_merged_df.shape[0])):\n",
    "    spoilers = not_multi_merged_df.loc[n].tolist()\n",
    "    data = [PROMPT.format(test_not_multi.loc[n, \"question\"], i, test_not_multi.loc[n, \"context\"]) for i in spoilers]\n",
    "    input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "\n",
    "    not_multi_selected_spoilers.append(spoilers[outputs.logits.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:21<00:00,  7.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "multi_selected_spoilers = []\n",
    "test_multi = test[test[\"type\"] == \"multi\"]\n",
    "tmp_multi = test_multi.reset_index(drop=True)\n",
    "for n in tqdm(range(multi_merged_df.shape[0])):\n",
    "    spoilers = multi_merged_df.loc[n].tolist()\n",
    "    data = [PROMPT.format(tmp_multi.loc[n, \"question\"], i, tmp_multi.loc[n, \"context\"]) for i in spoilers]\n",
    "    input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "\n",
    "    multi_selected_spoilers.append(spoilers[outputs.logits.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_13565/235532871.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_multi[\"spoiler\"] = test_multi[\"answers\"].apply(\n"
     ]
    }
   ],
   "source": [
    "# vicuna_output = pd.read_csv(\n",
    "#     \"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\"\n",
    "# )\n",
    "\n",
    "# vicuna_output = vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)[\n",
    "#     test[\"type\"] == \"multi\"\n",
    "# ]\n",
    "test_multi[\"spoiler\"] = test_multi[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))\n",
    "test_not_multi[\"spoiler\"] = test_not_multi[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.44303314639062596,\n",
       " 'precision': 0.9096897679422549,\n",
       " 'recall': 0.913005078852418,\n",
       " 'f1': 0.9108124781354718,\n",
       " 'exact_match': 0.3208502024291498,\n",
       " 'meteor': 0.5301155410177051}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import prepare_stats\n",
    "\n",
    "pred = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(not_multi_selected_spoilers, columns=[\"spoiler\"]),\n",
    "        pd.DataFrame(multi_selected_spoilers, columns=[\"spoiler\"]),\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "ref = pd.concat([test_not_multi, test_multi]).reset_index(drop=True)\n",
    "prepare_stats(ref, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prepare_stats(ref, pred)\n",
    "search_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mateusz15wozny/master_thesis/results/tables/regressor.csv\"\n",
    "df = pd.read_csv(path)\n",
    "search_df[\"model_name\"] = \"regressor-with-deberta-and-llms-and-new-data\"\n",
    "search_df[\n",
    "    \"description\"\n",
    "] = \"Use regressor finetuned on data from best models to select spoiler: for types phrase and passage from deberta and vicuna (prompt per type), for multi from llama and 2 vicuna\"\n",
    "search_df = search_df[[\"model_name\", \"bleu\", \"meteor\", \"exact_match\", \"recall\", \"f1\", \"precision\", \"description\"]]\n",
    "\n",
    "pd.concat([df, search_df], ignore_index=True).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"not multi deberta, 2 vicuna, llama and regressor v3\") as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "log_to_mlflow(\"\", prepare_stats(ref, pred), run_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = \"/home/mateusz15wozny/master_thesis/spoiler_generation/regressor/best-model-deberta-finetune-v2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=1).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"For given question:\\n {} \\nanswer:\\n {} \\ncontext:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the coolest feature that the Oregon Home includes?\n"
     ]
    }
   ],
   "source": [
    "n = 21\n",
    "spoilers = merged_df.loc[n].tolist()\n",
    "data = [PROMPT.format(test.loc[n, \"question\"], i, test.loc[n, \"context\"]) for i in spoilers]\n",
    "input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_test = test[original_df.loc[test[\"id\"] - 1].reset_index(drop=True)[\"tags\"] != \"multi\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 988/988 [02:57<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "selected_spoilers = []\n",
    "for n in tqdm(range(merged_df.shape[0])):\n",
    "    spoilers = merged_df.loc[n].tolist()\n",
    "    data = [PROMPT.format(test.loc[n, \"question\"], i, test.loc[n, \"context\"]) for i in spoilers]\n",
    "    input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "\n",
    "    selected_spoilers.append(spoilers[outputs.logits.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "tmp = original_df.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "pd.concat([test[tmp[\"tags\"] != \"multi\"], test[tmp[\"tags\"] == \"multi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.loc[pd.concat([test[tmp[\"tags\"] != \"multi\"], test[tmp[\"tags\"] == \"multi\"]]).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025475436780943023"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import calculate_bleu\n",
    "\n",
    "calculate_bleu(\n",
    "    test,\n",
    "    pred.loc[pd.concat([test[tmp[\"tags\"] != \"multi\"], test[tmp[\"tags\"] == \"multi\"]]).index],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Use deberta v2 regressor for llama, vicuna and opt\") as run:\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prepare_stats(test, pd.DataFrame(selected_spoilers, columns=[\"spoiler\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.3933260781647434,\n",
       " 'precision': 0.9020928325440719,\n",
       " 'recall': 0.9053516111634521,\n",
       " 'f1': 0.9031291687295504,\n",
       " 'exact_match': 0.2783400809716599,\n",
       " 'meteor': 0.4940156110653304}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prepare_stats(test, pd.DataFrame(selected_spoilers, columns=[\"spoiler\"]))\n",
    "search_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.393326</td>\n",
       "      <td>0.902093</td>\n",
       "      <td>0.905352</td>\n",
       "      <td>0.903129</td>\n",
       "      <td>0.27834</td>\n",
       "      <td>0.494016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bleu  precision    recall        f1  exact_match    meteor\n",
       "0  0.393326   0.902093  0.905352  0.903129      0.27834  0.494016"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = prepare_stats(test, pd.DataFrame(selected_spoilers, columns=[\"spoiler\"]))\n",
    "# search_df = pd.DataFrame([results])\n",
    "path = \"/home/mateusz15wozny/master_thesis/results/tables/regressor.csv\"\n",
    "df = pd.read_csv(path)\n",
    "search_df[\"model_name\"] = \"regressor-v5\"\n",
    "search_df[\"description\"] = \"Use regressor for llama (one common prompt), vicuna (one common prompt) and opt(prompt per type)\"\n",
    "search_df = search_df[[\"model_name\", \"bleu\", \"meteor\", \"exact_match\", \"recall\", \"f1\", \"precision\", \"description\"]]\n",
    "\n",
    "pd.concat([df, search_df], ignore_index=True).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor = calculate_meteor(test, pd.DataFrame(selected_spoilers, columns=[\"spoiler\"]))\n",
    "log_to_mlflow(\"\", {\"meteor\": meteor}, \"86b8ff84bf2e497e821722d14585904b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>merged_df = pd.concat(                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 │   </span>[                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>deberta_baseline[mixed[<span style=\"color: #808000; text-decoration-color: #808000\">\"tags\"</span>] != <span style=\"color: #808000; text-decoration-color: #808000\">\"multi\"</span>][<span style=\"color: #808000; text-decoration-color: #808000\">\"spoiler\"</span>].apply(preprocess_func),        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 │   │   </span>vicuna_output[mixed[<span style=\"color: #808000; text-decoration-color: #808000\">\"tags\"</span>] == <span style=\"color: #808000; text-decoration-color: #808000\">\"multi\"</span>][<span style=\"color: #808000; text-decoration-color: #808000\">\"spoiler\"</span>].apply(preprocess_func),           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 │   </span>]                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>).to_frame()                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'mixed'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mmerged_df = pd.concat(                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   \u001b[0m[                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[2m│   │   \u001b[0mdeberta_baseline[mixed[\u001b[33m\"\u001b[0m\u001b[33mtags\u001b[0m\u001b[33m\"\u001b[0m] != \u001b[33m\"\u001b[0m\u001b[33mmulti\u001b[0m\u001b[33m\"\u001b[0m][\u001b[33m\"\u001b[0m\u001b[33mspoiler\u001b[0m\u001b[33m\"\u001b[0m].apply(preprocess_func),        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   │   \u001b[0mvicuna_output[mixed[\u001b[33m\"\u001b[0m\u001b[33mtags\u001b[0m\u001b[33m\"\u001b[0m] == \u001b[33m\"\u001b[0m\u001b[33mmulti\u001b[0m\u001b[33m\"\u001b[0m][\u001b[33m\"\u001b[0m\u001b[33mspoiler\u001b[0m\u001b[33m\"\u001b[0m].apply(preprocess_func),           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m│   \u001b[0m]                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m).to_frame()                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'mixed'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.concat(\n",
    "    [\n",
    "        deberta_baseline[mixed[\"tags\"] != \"multi\"][\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        vicuna_output[mixed[\"tags\"] == \"multi\"][\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "    ]\n",
    ").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Select non multi spoilers from baseline and multi from vicuna\") as run:\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_mlflow(\"\", prepare_stats(test, merged_df), run_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"For given question:\\n{question}\\nchoose what answer is better\\n\\n\\n## Answer1:\\n{ans1}\\n\\n## Answer2:\\n{ans2}\\n\\n## Context:\\n{context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def preprocess_func(x: str) -> str:\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    document = re.sub(r\"\\W\", \" \", x)\n",
    "    document = re.sub(r\"^b\\s+\", \"\", document)\n",
    "\n",
    "    document = document.lower()\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    return \" \".join(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spoiler_generation.utils.dataset_class import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/test_2.json\")\n",
    "test_not_multi = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/type_based_clf/not_multi/test.json\")\n",
    "\n",
    "not_multi_vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "not_multi_vicunav2_output = (\n",
    "    not_multi_vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] != \"multi\"].reset_index(drop=True)\n",
    ")\n",
    "multi_vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "multi_vicunav2_output = multi_vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "multi_vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "multi_vicuna_output = multi_vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "multi_llama_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-finetuned/output.csv\")\n",
    "multi_llama_output = multi_llama_output.loc[test[\"id\"] - 1].reset_index(drop=True)[test[\"type\"] == \"multi\"].reset_index(drop=True)\n",
    "not_multi_output = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta/checkpoint-1293/output.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicuna_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-finetuned/output.csv\")\n",
    "vicunav2_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/vicuna-13b-new-prompt/output.csv\")\n",
    "llama_output = pd.read_csv(\"/home/mateusz15wozny/master_thesis/models/llama-13b-finetuned/output.csv\")\n",
    "\n",
    "\n",
    "test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/hf_qa/vicuna/test.json\")\n",
    "original_df = Dataset.from_jsonl(\"/home/mateusz15wozny/master_thesis/data/test.jsonl\").df\n",
    "deberta_full = pd.read_json(\n",
    "    \"/home/mateusz15wozny/master_thesis/models/not-multi-deberta-v2/full_output.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"spoiler\"] = test[\"answers\"].apply(lambda x: \" \".join([record[\"text\"][0] for record in x]))\n",
    "vicuna_output = vicuna_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "vicunav2_output = vicunav2_output.loc[test[\"id\"] - 1].reset_index(drop=True)\n",
    "llama_output = llama_output.loc[test[\"id\"] - 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_path = \"/home/mateusz15wozny/master_thesis/spoiler_generation/classificator/distilbert-base-v3\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test = pd.read_json(\"/home/mateusz15wozny/master_thesis/data/llama_generation/test.json\").loc[test[\"id\"] - 1]\n",
    "llama_test.rename(columns={\"output\": \"spoiler\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test_not_multi = llama_test[llama_test[\"type\"] != \"multi\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test_multi = llama_test[llama_test[\"type\"] == \"multi\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_multi_merged_df = pd.DataFrame(\n",
    "    zip(not_multi_output[\"spoiler\"].apply(Dataset.preprocess_func), not_multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func)),\n",
    "    columns=[\"ans1\", \"ans2\"],\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:17<00:00, 47.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "not_multi_selected_spoilers = []\n",
    "for n in tqdm(range(not_multi_merged_df.shape[0])):\n",
    "    spoilers = not_multi_merged_df.loc[n].tolist()\n",
    "    if spoilers[0] == \"\":\n",
    "        not_multi_selected_spoilers.append(spoilers[1])\n",
    "        continue\n",
    "    if spoilers[1] == \"\":\n",
    "        not_multi_selected_spoilers.append(spoilers[0])\n",
    "        continue\n",
    "    data = [PROMPT.format(question=llama_test_not_multi.iloc[n, 1], ans1=spoilers[0], ans2=spoilers[1], context=llama_test.iloc[n, 0])]\n",
    "    input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "\n",
    "    not_multi_selected_spoilers.append(spoilers[1 - outputs.logits.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test_not_multi.rename(columns={\"output\": \"spoiler\"}, inplace=True)\n",
    "llama_test_not_multi.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        multi_vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        multi_llama_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "    ),\n",
    "    columns=[\"ans1\", \"ans2\"],\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:03<00:00, 44.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "multi_selected_spoilers = []\n",
    "for n in tqdm(range(multi_merged_df.shape[0])):\n",
    "    spoilers = multi_merged_df.loc[n].tolist()\n",
    "    score = [0] * len(spoilers)\n",
    "    for comb in itertools.combinations(range(len(spoilers)), 2):\n",
    "        if spoilers[comb[0]] == \"\":\n",
    "            score[comb[1]] += 1\n",
    "            continue\n",
    "        if spoilers[comb[1]] == \"\":\n",
    "            score[comb[0]] += 1\n",
    "            continue\n",
    "        data = [\n",
    "            PROMPT.format(\n",
    "                question=llama_test_multi.iloc[n, 1], ans1=spoilers[comb[0]], ans2=spoilers[comb[1]], context=llama_test.iloc[n, 0]\n",
    "            )\n",
    "        ]\n",
    "        input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids)\n",
    "        if outputs.logits.argmax() == 1:\n",
    "            score[comb[0]] += 1\n",
    "        else:\n",
    "            score[comb[1]] += 1\n",
    "\n",
    "    multi_selected_spoilers.append(spoilers[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(\n",
    "    zip(\n",
    "        vicuna_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        # vicunav2_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "        llama_output[\"spoiler\"].apply(Dataset.preprocess_func),\n",
    "    )\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regressor-3-models-v0</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>description</th>\n",
       "      <th>use_type</th>\n",
       "      <th>train_on_new_data</th>\n",
       "      <th>opt-13B-v1</th>\n",
       "      <th>llama-13B-v1</th>\n",
       "      <th>vicuna-13B-v1</th>\n",
       "      <th>vicuna-13B-v2</th>\n",
       "      <th>deberta-finetuned-v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regressor-v0</td>\n",
       "      <td>0.394793</td>\n",
       "      <td>0.486069</td>\n",
       "      <td>0.281377</td>\n",
       "      <td>0.904139</td>\n",
       "      <td>0.900080</td>\n",
       "      <td>0.897016</td>\n",
       "      <td>Use regressor for llama and vicuna which have ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regressor-v1</td>\n",
       "      <td>0.421308</td>\n",
       "      <td>0.517158</td>\n",
       "      <td>0.292510</td>\n",
       "      <td>0.909114</td>\n",
       "      <td>0.905110</td>\n",
       "      <td>0.902059</td>\n",
       "      <td>Use regressor for llama (one common prompt), v...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deberta-for-2-types-and-vicuna-for-1</td>\n",
       "      <td>0.422794</td>\n",
       "      <td>0.506421</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>0.908095</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.910297</td>\n",
       "      <td>Use deberta to generate spoilers for types phr...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regressor-v2</td>\n",
       "      <td>0.448089</td>\n",
       "      <td>0.534837</td>\n",
       "      <td>0.319838</td>\n",
       "      <td>0.913540</td>\n",
       "      <td>0.911827</td>\n",
       "      <td>0.911183</td>\n",
       "      <td>Use regressor to select spoiler: for types phr...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regressor-v3</td>\n",
       "      <td>0.411760</td>\n",
       "      <td>0.509925</td>\n",
       "      <td>0.285425</td>\n",
       "      <td>0.908310</td>\n",
       "      <td>0.904619</td>\n",
       "      <td>0.901942</td>\n",
       "      <td>Use regressor finetuned on data from best mode...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regressor-v4</td>\n",
       "      <td>0.418017</td>\n",
       "      <td>0.515851</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.909038</td>\n",
       "      <td>0.905336</td>\n",
       "      <td>0.902617</td>\n",
       "      <td>Use regressor finetuned on data from best mode...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regressor-v5</td>\n",
       "      <td>0.396488</td>\n",
       "      <td>0.493906</td>\n",
       "      <td>0.284413</td>\n",
       "      <td>0.905954</td>\n",
       "      <td>0.904187</td>\n",
       "      <td>0.903616</td>\n",
       "      <td>Use regressor finetuned on data from best mode...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regressor-v6</td>\n",
       "      <td>0.401651</td>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.286437</td>\n",
       "      <td>0.907015</td>\n",
       "      <td>0.905197</td>\n",
       "      <td>0.904550</td>\n",
       "      <td>Use regressor finetuned on data from best mode...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regressor-v7</td>\n",
       "      <td>0.444519</td>\n",
       "      <td>0.532024</td>\n",
       "      <td>0.320850</td>\n",
       "      <td>0.913477</td>\n",
       "      <td>0.911488</td>\n",
       "      <td>0.910561</td>\n",
       "      <td>Use regressor finetuned on data from best mode...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  regressor-3-models-v0      bleu    meteor  exact_match  \\\n",
       "0                          regressor-v0  0.394793  0.486069     0.281377   \n",
       "1                          regressor-v1  0.421308  0.517158     0.292510   \n",
       "2  deberta-for-2-types-and-vicuna-for-1  0.422794  0.506421     0.302632   \n",
       "3                          regressor-v2  0.448089  0.534837     0.319838   \n",
       "4                          regressor-v3  0.411760  0.509925     0.285425   \n",
       "5                          regressor-v4  0.418017  0.515851     0.289474   \n",
       "6                          regressor-v5  0.396488  0.493906     0.284413   \n",
       "7                          regressor-v6  0.401651  0.499391     0.286437   \n",
       "8                          regressor-v7  0.444519  0.532024     0.320850   \n",
       "\n",
       "     recall        f1  precision  \\\n",
       "0  0.904139  0.900080   0.897016   \n",
       "1  0.909114  0.905110   0.902059   \n",
       "2  0.908095  0.908629   0.910297   \n",
       "3  0.913540  0.911827   0.911183   \n",
       "4  0.908310  0.904619   0.901942   \n",
       "5  0.909038  0.905336   0.902617   \n",
       "6  0.905954  0.904187   0.903616   \n",
       "7  0.907015  0.905197   0.904550   \n",
       "8  0.913477  0.911488   0.910561   \n",
       "\n",
       "                                         description  use_type  \\\n",
       "0  Use regressor for llama and vicuna which have ...     False   \n",
       "1  Use regressor for llama (one common prompt), v...     False   \n",
       "2  Use deberta to generate spoilers for types phr...      True   \n",
       "3  Use regressor to select spoiler: for types phr...      True   \n",
       "4  Use regressor finetuned on data from best mode...     False   \n",
       "5  Use regressor finetuned on data from best mode...     False   \n",
       "6  Use regressor finetuned on data from best mode...     False   \n",
       "7  Use regressor finetuned on data from best mode...     False   \n",
       "8  Use regressor finetuned on data from best mode...      True   \n",
       "\n",
       "   train_on_new_data opt-13B-v1 llama-13B-v1  vicuna-13B-v1 vicuna-13B-v2  \\\n",
       "0              False                    True           True                 \n",
       "1              False                    True           True          True   \n",
       "2              False                                   True                 \n",
       "3              False                    True           True          True   \n",
       "4               True                    True           True                 \n",
       "5               True                    True           True          True   \n",
       "6               True       True         True           True                 \n",
       "7               True       True         True           True          True   \n",
       "8               True                    True           True          True   \n",
       "\n",
       "  deberta-finetuned-v3  \n",
       "0                       \n",
       "1                       \n",
       "2                 True  \n",
       "3                 True  \n",
       "4                       \n",
       "5                       \n",
       "6                       \n",
       "7                       \n",
       "8                 True  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/home/mateusz15wozny/master_thesis/results/tables/regressor.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 988/988 [00:21<00:00, 45.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "selected_spoilers = []\n",
    "for n in tqdm(range(merged_df.shape[0])):\n",
    "    spoilers = merged_df.loc[n].tolist()\n",
    "    score = [0] * len(spoilers)\n",
    "    for comb in itertools.combinations(range(len(spoilers)), 2):\n",
    "        if spoilers[comb[0]] == \"\":\n",
    "            score[comb[1]] += 1\n",
    "            continue\n",
    "        if spoilers[comb[1]] == \"\":\n",
    "            score[comb[0]] += 1\n",
    "            continue\n",
    "        data = [\n",
    "            PROMPT.format(question=llama_test.iloc[n, 1], ans1=spoilers[comb[0]], ans2=spoilers[comb[1]], context=llama_test.iloc[n, 0])\n",
    "        ]\n",
    "        input_ids = tokenizer(data, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids)\n",
    "        if outputs.logits.argmax() == 1:\n",
    "            score[comb[0]] += 1\n",
    "        else:\n",
    "            score[comb[1]] += 1\n",
    "\n",
    "    selected_spoilers.append(spoilers[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.43455372191988867,\n",
       " 'precision': 0.9114617712584584,\n",
       " 'recall': 0.9109391218978866,\n",
       " 'f1': 0.9106571890323268,\n",
       " 'exact_match': 0.31275303643724695,\n",
       " 'meteor': 0.5198940468784699}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stats import prepare_stats\n",
    "\n",
    "pred = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(not_multi_selected_spoilers, columns=[\"spoiler\"]),\n",
    "        pd.DataFrame(multi_selected_spoilers, columns=[\"spoiler\"]),\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "ref = pd.concat([llama_test_not_multi, llama_test_multi]).reset_index(drop=True)\n",
    "prepare_stats(ref, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "results = prepare_stats(llama_test, pd.DataFrame(selected_spoilers, columns=[\"spoiler\"]))\n",
    "search_df = pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4005121569512152,\n",
       " 'precision': 0.9002666785287471,\n",
       " 'recall': 0.9057403748575975,\n",
       " 'f1': 0.9025039885811478,\n",
       " 'exact_match': 0.2834008097165992,\n",
       " 'meteor': 0.4927087598212761}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mateusz15wozny/master_thesis/results/tables/classificator.csv\"\n",
    "df = pd.read_csv(path)\n",
    "search_df[\"model_name\"] = \"classifier-for-2-models-not-use-type\"\n",
    "search_df[\"description\"] = \"Use classifier for llama and vicuna which have one common prompt for all spoiler types\"\n",
    "search_df = search_df[[\"model_name\", \"bleu\", \"meteor\", \"exact_match\", \"recall\", \"f1\", \"precision\", \"description\"]]\n",
    "\n",
    "pd.concat([df, search_df], ignore_index=True).to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
